---
layout: page
title: MMC
description: Making Meta-Data Count
img: assets/img/3.jpg
importance: 2
category: work
---

Machine learning has shown promising results in medical image diagnosis, at times with claims of expert-level performance. The availability of large public datasets have shifted the interest of the medical community to high-performance algorithms. However, little attention is paid to the quality of the data or annotations. Algorithms with high reported performances have been shown to suffer from overfitting or shortcuts, i.e. spurious correlations between artifacts in images and diagnostic labels. Examples include pen marks in skin lesion classification, patient position in detection of COVID-19, and chest drains in pneumothorax classification. Performance may appear high when training and evaluating on data with shortcuts, but degraded when the shortcut is removed. This happens because the algorithm cannot generalize based on the actual features related to the diagnosis.

Our goal with this project is to improve the understanding of these algorithms for a fairer and safer deployment in a clinical setting. 
We plan to:
* research fairness metrics for patient subgroups, such as age, sex or ethnicity, to investigate the equity of the algorithm ‚öñÔ∏è.
* investigate meta-data-aware methods to try to avoid learning biases or shortcuts ‚öîÔ∏èüõ°.

